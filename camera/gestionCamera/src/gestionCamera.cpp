#include <stdio.h>
#include <iostream>

#include <opencv2/opencv.hpp>
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/video/background_segm.hpp>
#include <math.h>
#include <jni_TraitementJNI.h>
#include <jni.h>
#include <windows.h>

using namespace cv;
using namespace std;

class Blob{
public:
	Point pointBasDroite, pointHautGauche;
};
//
std::map<String,vector<Blob> > blobList;
int traitementCamera(String adresseCamera, bool debug, String repertoireImages){
	//global variables
	Mat frame; //current frame
	Mat resize_blur_Img;
	Mat foreground; //Image du premier plan
	Mat binaryImg;
	//Mat TestImg;
	Mat ContourImg; //fg mask fg mask generated by MOG2 method
	cv::Ptr<BackgroundSubtractor> mOG2 = createBackgroundSubtractorMOG2(300,32,false);

	//Capture d'un fichier pour les tests,
	//d'une webcam pour la mise en prod
	VideoCapture stream1;
	if(isdigit(adresseCamera.c_str()[0])){
		stream1=VideoCapture(atoi(adresseCamera.c_str()));
	}else{
		stream1=VideoCapture(adresseCamera);
	}

	//Pour nettoyer les pixels isolés faux positif
	Mat element = getStructuringElement(MORPH_RECT, Size(7, 7), Point(3,3) );
	if(blobList.find(adresseCamera)->first==NULL){
		blobList.insert(std::pair<String,vector<Blob> >(adresseCamera,vector<Blob>()));
	}
	int i=1;
	std::map<String, vector<Blob> >::iterator listeBlob=blobList.find(adresseCamera);
	while (true) {
		listeBlob->second.clear();
		if((stream1.read(frame))){ //get one frame form video
			//Resize
			//Reduire l'image peut accelerer le traitement
			resize(frame, resize_blur_Img, Size(frame.size().width/1, frame.size().height/1) );
			//Leger flou pour éliminer des détails qui feraient de faux positifs
			blur(resize_blur_Img, resize_blur_Img, Size(4,4) );
			//Background subtraction
			mOG2->apply(resize_blur_Img, foreground, -1);//,-0.5);

			// Suppression des points isolés
			morphologyEx(foreground, binaryImg, CV_MOP_CLOSE, element);

			//Suppression de l'ombre
			//Sur le foreground l'ombre est grise alors que l'objet lui même est blanc
			threshold(binaryImg, binaryImg, 128, 255, CV_THRESH_BINARY);

			//On essaye de strucuturer les objets trouvés par contours
			vector<vector<Point> > contours;
			findContours(binaryImg,
					contours, // a vector of contours
					CV_RETR_EXTERNAL, // retrieve the external contours
					CV_CHAIN_APPROX_NONE); // all pixels of each contours
			vector<vector<Point> > contours_poly( contours.size() );
			vector<Rect> boundRect( contours.size() );
			vector<Point2f>center( contours.size() );
			vector<float>radius( contours.size() );

			for( unsigned int index = 0; index < contours.size(); index++ )
			{
				approxPolyDP( Mat(contours[index]), contours_poly[index], 3, true );
			}

			if(contours_poly.size()<200){
				for( unsigned int j = 0; j < contours_poly.size(); j++ )
				{
					if(contourArea(contours_poly[j])>400){
						boundRect[j] = boundingRect( Mat(contours_poly[j]) );
						Blob blob = Blob();
						blob.pointBasDroite=boundRect[j].br();
						blob.pointHautGauche=boundRect[j].tl();
						listeBlob->second.push_back(blob);
						//						printf("Traitement X1:%i Y1:%i X2:%i Y2:%i\n",blob.pointHautGauche.x, blob.pointHautGauche.y, blob.pointBasDroite.x, blob.pointBasDroite.y);
						if(debug && ((i%25)==0)){
							Scalar color = Scalar(0, 0, 255);
							rectangle( frame, boundRect[j].tl(), boundRect[j].br(), color, 2, 8, 0 );
							std::stringstream nomFichierSortie1;
							std::stringstream nomFichierSortie2;
							nomFichierSortie1 << repertoireImages<<"/foreground/image_" << i << ".jpg";
							imwrite(nomFichierSortie1.str(), foreground);
							nomFichierSortie2 << repertoireImages<<"/image_" << i << ".jpg";
							imwrite(nomFichierSortie2.str(), frame);
						}
					}
				}
			}
			Sleep(40);
		}
		i++;
	}
	return true;
}
JNIEXPORT void JNICALL Java_jni_TraitementJNI_lancerCapture
(JNIEnv *env, jobject object, jstring name, jstring repertoireImages, jboolean debug){
	const char *str= env->GetStringUTFChars(name,0);
	const char *repertoire= env->GetStringUTFChars(repertoireImages,0);

	printf("Mode debug :%s\n", debug ? "true" : "false");
	printf("Nom du fichier: %s\n", str);
	traitementCamera(str, debug, repertoire);
	//need to release this string when done with it in order to
	//avoid memory leak
	env->ReleaseStringUTFChars(name, str);
}
JNIEXPORT jobjectArray JNICALL Java_jni_TraitementJNI_getBlobs
(JNIEnv *env, jobject object, jstring adresseCamera){
	jobjectArray result;
	const char *str= env->GetStringUTFChars(adresseCamera,0);
	env->ReleaseStringUTFChars(adresseCamera, str);
	std::map<String, vector<Blob> >::iterator iteratorBlob=blobList.find(str);
	vector<Blob> listeBlob = iteratorBlob->second;
	jclass cls;
	cls = env->FindClass("obj/Blob");
	if(cls==NULL){
		printf("classe NULL");
	}
	result=env->NewObjectArray(listeBlob.size(),cls,NULL);
	for(unsigned int i=0;i<listeBlob.size();i++){
		jmethodID constructor;
		jint args[4];
		jobject object;
		constructor = env->GetMethodID(cls, "<init>", "(IIII)V");
		Blob blob = listeBlob[i];
		args[0] = blob.pointHautGauche.x;
		args[1] = blob.pointHautGauche.y;
		args[2] = blob.pointBasDroite.x;
		args[3] = blob.pointBasDroite.y;
//		printf("DLL blob X1:%i Y1:%i X2:%i Y2:%i\n",blob.pointHautGauche.x, blob.pointHautGauche.y, blob.pointBasDroite.x, blob.pointBasDroite.y);
//		printf("DLL ARGS X1:%i Y1:%i X2:%i Y2:%i\n",args[0], args[1], args[2], args[3]);
		object = env->NewObject(cls, constructor, args[0], args[1], args[2], args[3]);
		env->SetObjectArrayElement(result, i, object);
		return result;
	}
}
